{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "lstm_hot_coding.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxpEVZQJ-59Q"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import re\n",
        "import collections\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvZDwsBZ-59T",
        "outputId": "4daa5adb-461c-42cf-fc8d-b44988366be2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "repo_url = 'https://raw.githubusercontent.com/elaynelemos/Lex-POS-Approach/master'\n",
        "correctSentFile = f'{repo_url}/combined_tagged_lang_selected_entries.csv'\n",
        "\n",
        "corrSent = pd.read_csv(correctSentFile,header=None,sep=\"\\t\")\n",
        "corrSent = corrSent[2]\n",
        "tempSent = []\n",
        "print(len(corrSent))\n",
        "for sent in corrSent:\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(r'\\.{1,}',r'',sent)\n",
        "    tempSent.append(sent)\n",
        "\n",
        "bl = list(range(len(corrSent)))\n",
        "\n",
        "random.shuffle(bl)\n",
        "corrSent = []\n",
        "for j in bl :\n",
        "    corrSent.append(tempSent[j])\n",
        "    \n",
        "print(corrSent[0])\n",
        "print(tempSent[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99685\n",
            "prp i vbd jj cc prp i vbd jj to vb jj nns\n",
            "jj nn innn on prpd your jj nn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llAXqLZm-59U",
        "outputId": "12ed8842-7cec-483b-93d1-d752f522303d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inCorrectSentFile = f'{repo_url}/combined_tagged_specific_error_lang_selected_entries.csv'\n",
        "IncorrSent = pd.read_csv(inCorrectSentFile,header=None,sep=\"\\t\")\n",
        "IncorrSent = IncorrSent[2]\n",
        "tempSent = []\n",
        "\n",
        "for sent in IncorrSent:\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(r'\\.{1,}',r'',sent)\n",
        "    tempSent.append(sent)\n",
        "    \n",
        "\n",
        "    \n",
        "inCorrectSentFile = f'{repo_url}/combined_tagged_general_error_lang_selected_entries.csv'\n",
        "IncorrSent = pd.read_csv(inCorrectSentFile,header=None,sep=\"\\t\")\n",
        "#IncorrSent = IncorrSent[0]\n",
        "IncorrSent = IncorrSent[2]\n",
        "\n",
        "for sent in IncorrSent:\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(r'\\.{1,}',r'',sent)\n",
        "    tempSent.append(sent)\n",
        "    \n",
        "\n",
        "\n",
        "bl = list(range(len(tempSent)))\n",
        "random.shuffle(bl)\n",
        "\n",
        "IncorrSent = []\n",
        "for j in bl :\n",
        "    IncorrSent.append(tempSent[j])\n",
        "    \n",
        "\n",
        "print(len(IncorrSent))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4roixD34-59V",
        "outputId": "d022e776-72f8-47bd-e996-d9c02b108745",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corrSent = np.array(corrSent)\n",
        "\n",
        "zeros = np.zeros((len(corrSent),1),dtype=int) #creating labels of correct sentences\n",
        "corrSent = np.reshape(corrSent,(len(corrSent),1))\n",
        "corrSent = np.append(corrSent,zeros,axis=1) #\n",
        "print(corrSent[2])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['innn before dt this nn ,' '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1K8ZyH5-59V",
        "outputId": "7e47fe53-fd15-454b-9d0f-2852f998033c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "IncorrSent = np.array(IncorrSent)\n",
        "ones = np.ones((len(IncorrSent),1),dtype=int) #creating labels of incorrect sentences\n",
        "IncorrSent = np.reshape(IncorrSent,(len(IncorrSent),1))\n",
        "IncorrSent = np.append(IncorrSent,ones,axis=1)\n",
        "print(IncorrSent[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rb , nn rb vb vbn' '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-edr4wc-59V",
        "outputId": "8c8d16f3-ed2c-4da4-dc2a-950a42e75f2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#partition for specific errors set\n",
        "'''\n",
        "trainSet = np.append(corrSent[0:40000,],IncorrSent[0:25000,],axis=0)\n",
        "trainSet = np.append(trainSet[0:65000,],IncorrSent[10000:25000,],axis=0)\n",
        "testSet = np.append(corrSent[40000:50000,],IncorrSent[25000:31623,],axis=0)\n",
        "testSet = np.append(testSet[0:16623,],IncorrSent[11000:14377,],axis=0)\n",
        "'''\n",
        "#partition for combined errors set\n",
        "trainSet = np.append(corrSent[0:48000,],IncorrSent[0:24000,],axis=0)\n",
        "trainSet = np.append(trainSet[0:72000,],IncorrSent[40000:64000,],axis=0)\n",
        "testSet = np.append(corrSent[48000:60000,],IncorrSent[24000:30000,],axis=0)\n",
        "testSet = np.append(testSet[0:18000,],IncorrSent[64000:70000,],axis=0)\n",
        "\n",
        "'''\n",
        "#partition for general errors set\n",
        "trainSet = np.append(corrSent[0:48000,],IncorrSent[0:48000,],axis=0)\n",
        "testSet = np.append(corrSent[48000:60000,],IncorrSent[48000:60000,],axis=0)\n",
        "'''\n",
        "print(len(trainSet))\n",
        "print(len(testSet))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96000\n",
            "24000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF8hPm2e-59W",
        "outputId": "94dd4ced-9969-497d-b108-3310c223e2b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words_counter = collections.Counter([word  for i in range(len(trainSet)) for word in trainSet[i][0].split()])\n",
        "#print(words_counter)\n",
        "print('{} English words.'.format(len([word  for i in range(len(trainSet)) for word in trainSet[i][0].split()])))\n",
        "print('{} unique English words.'.format(len(words_counter)))\n",
        "print(words_counter.most_common(10))\n",
        "print(words_counter)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "966682 English words.\n",
            "1911 unique English words.\n",
            "[('nn', 103639), ('prp', 81394), ('innn', 57452), ('dt', 55807), ('jj', 52457), ('i', 45054), ('rb', 43325), ('nnp', 37779), ('vbp', 34325), ('vb', 30240)]\n",
            "Counter({'nn': 103639, 'prp': 81394, 'innn': 57452, 'dt': 55807, 'jj': 52457, 'i': 45054, 'rb': 43325, 'nnp': 37779, 'vbp': 34325, 'vb': 30240, 'vbd': 28789, 'vbz': 26677, 'nns': 24090, 'the': 17743, 'to': 17417, 'prpd': 17138, ',': 16356, 'cc': 14579, 'a': 14435, 'it': 12568, 'vbg': 12436, 'my': 12422, 'vbn': 10864, 'in': 9781, 'md': 9428, 'an': 9072, 'of': 7738, 'for': 6474, 'am': 6122, 'you': 5891, 'this': 5795, 'are': 4785, 'have': 4671, 'that': 4270, 'me': 4130, 'wrb': 3917, 'on': 3773, 'we': 3757, 'at': 3739, 'wp': 3293, 'with': 3181, 'cd': 3056, 'about': 2924, 'pos': 2832, 'L': 2622, 'like': 2592, 'he': 2486, 'ex': 2308, 'A': 2236, 'they': 2136, 'from': 2080, 'she': 1967, 'do': 1958, 'rp': 1943, 'S': 1866, 'want': 1619, 'K': 1594, 'some': 1569, 'because': 1525, 'B': 1524, 'jjr': 1503, 'think': 1468, 'by': 1467, 'her': 1306, 'G': 1290, 'them': 1288, 'all': 1274, 'P': 1240, 'as': 1161, 'F': 1157, 'jjs': 1155, 'D': 1087, 'if': 1076, 'after': 1055, 'M': 1033, 'your': 1028, 'I': 1000, 'his': 934, 'N': 909, 'no': 897, 'wdt': 861, 'T': 858, 'our': 848, 'W': 817, 'H': 807, 'these': 807, 'hope': 799, 'rbr': 776, 'him': 766, 'their': 681, 'than': 678, 'R': 676, 'V': 657, '``': 653, 'every': 611, 'J': 555, 'know': 522, 'since': 519, 'feel': 516, 'before': 508, 'any': 503, 'love': 476, 'so': 474, 'myself': 438, 'us': 383, 'another': 379, 'uh': 374, 'need': 371, 'E': 364, 'each': 327, 'over': 319, 'pdt': 312, 'go': 306, 'live': 295, 'Y': 287, 'C': 279, 'ate': 268, 'around': 264, 'during': 259, 'though': 258, 'into': 256, 'rbs': 247, 'until': 222, 'without': 213, 'while': 209, 'both': 206, 'read': 199, 'through': 196, 'its': 196, 'between': 194, 'those': 193, 'wish': 175, 'get': 170, 'study': 166, 'use': 165, 'make': 164, 'nnps': 157, 'near': 144, 'wan': 143, 'say': 142, 'work': 140, 'wonder': 133, 'believe': 126, 'out': 123, 'although': 112, 'guess': 110, 'enjoy': 109, 'take': 107, 'see': 106, 'write': 102, 'off': 101, 'hate': 99, 'whether': 97, 'O': 96, 'ago': 93, 'come': 88, 'look': 87, 'ooof': 87, 'try': 85, 'under': 85, 'eat': 81, 'find': 78, 'drank': 78, 'fw': 74, 'miss': 72, 'offf': 71, 'aaa': 69, 'mean': 66, 'play': 65, 'next': 65, 'heard': 64, 'aaand': 64, 'thhhat': 64, 'recommend': 63, 'learn': 62, 'against': 62, 'correct': 62, 'among': 60, 'talk': 59, 'speak': 58, 'waaas': 58, 'start': 57, 'give': 57, 'listen': 56, 'except': 56, 'yourself': 55, 'help': 54, 'ttthat': 53, 'appreciate': 52, 'drink': 52, 'outside': 52, 'watch': 51, 'iiin': 51, 'above': 50, 'haaad': 50, 'wwwas': 50, 'become': 49, 'seem': 48, 'understand': 47, 'along': 45, 'below': 45, 'prefer': 44, 'wasss': 44, 'enjoyed': 42, 'behind': 42, 'annnd': 42, 'aaabout': 42, 'keep': 41, 'hear': 40, 'onnn': 40, 'per': 39, 'up': 39, 'anddd': 39, 'inside': 38, 'besides': 38, 'm': 37, 'run': 37, 'wennnt': 37, 'spend': 35, 'fooor': 35, 'weeent': 35, 'tell': 34, 'buy': 34, 'haddd': 34, 'worry': 33, 'remember': 33, 'leave': 33, 'isss': 33, 'guys': 32, 'iiis': 32, 'slept': 31, 'wenttt': 31, 'attt': 31, 'wear': 30, 'themselves': 30, 'plan': 30, 'abooout': 30, 'quit': 29, 'call': 29, 'agree': 29, 'dont': 28, 'put': 28, \"''\": 28, 'respect': 27, 'don': 27, 'itself': 27, 'abbbout': 27, 'within': 26, 'expect': 26, 'belong': 26, 'stay': 26, 'forrr': 26, 'visit': 25, 'aaat': 25, 'wwwent': 25, 'via': 24, 'throughout': 24, 'fffor': 24, 'ooon': 23, 'despite': 21, 'rode': 21, 'himself': 20, 'forget': 20, 'across': 20, 'meet': 19, 'wereee': 19, 'byyy': 19, 'sleep': 18, 'hurt': 18, 'pray': 18, 'lose': 18, 'toward': 18, 'suppose': 18, 'choose': 18, 'tooook': 18, 'digit': 17, 'felt': 17, 'decide': 17, 'admire': 17, 'teach': 17, 'walk': 17, 'continue': 17, 'regret': 17, 'gottt': 17, 'diddd': 17, 'wiiith': 17, 'werrre': 17, 'either': 16, 'wake': 16, 'herself': 16, 'overslept': 16, 'unlike': 16, 'abouuut': 16, 'withhh': 16, 'upon': 15, 'finish': 15, 'die': 15, 'ourselves': 15, 'liiike': 15, 'frrrom': 15, 'drive': 14, 'snow': 14, 'bring': 14, 'sell': 14, 'abouttt': 14, 'bbbut': 14, 'please': 13, 'understood': 13, 'beside': 13, 'check': 13, 'xd': 13, 'b': 13, 'ask': 13, 'buttt': 13, 'theee': 13, 'cook': 12, 'admit': 12, 'past': 12, 'sit': 12, 'stayed': 12, 'wait': 12, '$': 12, 'pay': 12, 'begin': 12, 'tend': 12, 'wore': 12, 'set': 12, 'diiid': 12, 'weeere': 12, 'felttt': 12, 'wittth': 12, 'asss': 12, 'travel': 11, 'join': 11, 'promise': 11, 'd': 11, 'appear': 11, 'envy': 11, 'Z': 11, 'attend': 11, 'realize': 11, 'suffer': 11, 'bet': 11, 'show': 11, 'dddid': 11, 'thaaat': 11, 'ttthe': 11, 'imagine': 10, 'lol': 10, 'everyday': 10, 've': 10, 'consider': 10, 'ran': 10, 'face': 10, 'dislike': 10, 'onto': 10, 'buuut': 10, 'thattt': 10, 'becauuuse': 10, 'bbbecause': 10, 'thhhe': 10, 'alllso': 10, 'back': 9, 'let': 9, 'disagree': 9, 'grow': 9, 'oneself': 9, 'pass': 9, \"'s\": 9, 'intend': 9, 'hold': 9, 'prepare': 9, 'beyond': 9, 'sooo': 9, 'send': 9, 'towards': 9, 'beeecause': 9, 'gooot': 9, 'lllike': 9, 'maddde': 9, 'swam': 8, 'friend': 8, 'meant': 8, 'change': 8, 'spread': 8, 'suggest': 8, 'cant': 8, 'laugh': 8, 'learnt': 8, 'turn': 8, 'chose': 8, 'deserve': 8, 'assume': 8, 'sang': 8, 'unless': 8, 'doubt': 8, 's': 8, 'born': 8, 'afraid': 8, 'aim': 8, 'founddd': 8, 'wwwith': 8, 'fffrom': 8, 'fffelt': 8, 'sawww': 8, 'boughhht': 8, 'saaaw': 8, 'saiiid': 8, 'becaaause': 8, 'forgot': 7, 'hahaha': 7, 'll': 7, 'exercise': 7, 'curry': 7, 'lack': 7, 'drunk': 7, 'self': 7, 'require': 7, 'eaten': 7, 'fall': 7, 'receive': 7, 'welcome': 7, 'care': 7, 'quarrel': 7, 'teacher': 7, 'celebrate': 7, 'notice': 7, 'o': 7, 'participate': 7, 'ssso': 7, 'becccause': 7, 'juuust': 7, 'thoughhht': 7, 'maaade': 7, 'aaas': 7, 'english': 7, 'bbby': 7, 'toooo': 7, 'beeeen': 7, 'nnnow': 7, 'yen': 6, 'fly': 6, 'upload': 6, 'hit': 6, 'insist': 6, 'draw': 6, 'earn': 6, 'relaxed': 6, 'enter': 6, 'happen': 6, 'chat': 6, 'communicate': 6, 'commute': 6, 'worth': 6, 'cry': 6, 'hung': 6, 'throw': 6, 'accept': 6, 'apologize': 6, 'therefore': 6, 'down': 6, 'wherever': 6, 'p': 6, 'pick': 6, 'thank': 6, 'glad': 6, 'tookkk': 6, 'jjjust': 6, 'alssso': 6, 'arrround': 6, 'agggo': 6, 'orrr': 6, 'improve': 6, 'tt': 6, 'ttthis': 6, 'aaall': 6, 'jussst': 6, 'founnnd': 6, \"'t\": 6, 'wwwere': 6, 'fooound': 6, 'boughttt': 6, 'onlyyy': 6, 'ifff': 6, 'allll': 6, 'good': 5, 'belive': 5, 'dreamt': 5, 'didnt': 5, 'swear': 5, 'ride': 5, 'follow': 5, 'introduce': 5, 'gon': 5, 'depend': 5, 'roll': 5, 'someday': 5, 'offer': 5, 'relax': 5, 'catch': 5, 'brush': 5, 'japanese': 5, 'shower': 5, 'soccer': 5, 'recognize': 5, 'ume': 5, 'cherry': 5, 'which': 5, 'degree': 5, 'mind': 5, 'serve': 5, 'sick': 5, 'sleepy': 5, 'smell': 5, 'uuup': 5, 'madeee': 5, 'oooften': 5, 'everrry': 5, 'fouuund': 5, 'ooor': 5, 'aaalso': 5, 'cameee': 5, 'cccame': 5, 'nooot': 5, 'watcheddd': 5, 'thhhough': 5, 'alsooo': 5, 'home': 5, 'fail': 4, 'n': 4, 'provide': 4, 'thought': 4, 'create': 4, 'stop': 4, 'ls': 4, 'arrive': 4, 'dare': 4, 'taught': 4, 'express': 4, 'deeply': 4, 're': 4, 'add': 4, 'gather': 4, 'rely': 4, 'ok': 4, 'return': 4, \"'cause\": 4, 'annoy': 4, 'move': 4, 'license': 4, 'nowadays': 4, 'carry': 4, 'complain': 4, 'played': 4, 'concentrate': 4, 'taste': 4, 'save': 4, 'drop': 4, 'hard': 4, 'bite': 4, 'couldn': 4, 'neither': 4, 'better': 4, 'essay': 4, 'waste': 4, 'nead': 4, 'once': 4, 'rain': 4, 'eve': 4, 'proud': 4, 'post': 4, 'support': 4, 'till': 4, 'ten': 4, 'whenever': 4, 'strange': 4, 'win': 4, 'brown': 4, 'fun': 4, 'refuse': 4, 'felllt': 4, 'busy': 4, 'knewww': 4, 'meeet': 4, 'thisss': 4, 'caaame': 4, 'hungry': 4, 'stillll': 4, 'arouuund': 4, 'thrrrough': 4, 'rent': 4, 'tttoo': 4, 'intooo': 4, 'agooo': 4, 'advance': 4, 'hearrrd': 4, 'verrry': 4, 'mettt': 4, 'starteddd': 4, 'visiteddd': 4, 'gggave': 4, 'eveeer': 4, 'veryyy': 4, 'seldom': 3, 'spilt': 3, 'desire': 3, 'surf': 3, 'close': 3, 'happend': 3, 'jog': 3, 'cheer': 3, 'contest': 3, 'touch': 3, 'educate': 3, 'broth': 3, 'likedthem': 3, 'record': 3, 'trust': 3, 'transcribe': 3, 'went': 3, 'bit': 3, 'perform': 3, 'criticize': 3, 'very': 3, 't': 3, 'lake': 3, 'rebuilt': 3, 'graduate': 3, 'search': 3, 'bid': 3, 'discover': 3, 'sound': 3, 'gain': 3, 'wave': 3, 'fit': 3, 'th': 3, 'rice': 3, 'sing': 3, 'end': 3, 'treat': 3, 'report': 3, 'soak': 3, 'dream': 3, 'pm': 3, 'shoud': 3, 'encourage': 3, 'little': 3, 'sneeze': 3, 'click': 3, 'u': 3, 'fel': 3, 'w': 3, 'spent': 3, 'contribute': 3, 'question': 3, 'represent': 3, 'occur': 3, 'log': 3, 'match': 3, 'hair': 3, 'anytime': 3, 'handle': 3, 'greet': 3, 'solve': 3, 'l': 3, 'elect': 3, 'spray': 3, 'break': 3, 'comment': 3, 'permit': 3, 'adore': 3, 'ya': 3, 'cough': 3, 'matsutake': 3, 'splash': 3, 'wrong': 3, 'mistook': 3, 'spicy': 3, 'sym': 3, 'fellll': 3, 'saiddd': 3, 'useeed': 3, 'sorry': 3, 'thousand': 3, 'friends': 3, 'aaaround': 3, 'begggan': 3, 'hhhas': 3, 'display': 3, 'tollld': 3, 'aaan': 3, 'mmmade': 3, 'trieeed': 3, 'stttill': 3, 'ppput': 3, 'askeeed': 3, 'usuallyyy': 3, 'lunch': 3, 'afffter': 3, 'yoga': 3, 'quite': 3, 'cake': 3, 'fffound': 3, 'tttook': 3, 'lead': 3, 'enjoyeddd': 3, 'frooom': 3, 'nottt': 3, 'frommm': 3, 'veeery': 3, 'cherish': 3, 'kneeew': 3, 'ttthough': 3, 'sssometimes': 3, 'iiinto': 3, 'oftennn': 3, 'found': 3, 'aaago': 3, 'lllost': 3, 'lookeeed': 3, 'deep': 3, 'annn': 3, 'watcheeed': 3, 'playeeed': 3, 'basketball': 3, 'whiiile': 3, 'absent': 3, 'befffore': 3, 'stayeddd': 3, 'flew': 2, 'misunderstand': 2, 'smile': 2, 'wannna': 2, 'steam': 2, 'min': 2, 'noise': 2, 'loose': 2, 'fixed': 2, 'revive': 2, 'did': 2, 'contrast': 2, 'exchange': 2, 'dodge': 2, 'bread': 2, 'stretch': 2, 'smoke': 2, 'kimono': 2, 'name': 2, 'baseball': 2, 'fake': 2, 'interlace': 2, 'perfect': 2, 'artist': 2, 'compare': 2, 'one': 2, 'count': 2, 'bike': 2, 'borrow': 2, 'lazy': 2, 'bother': 2, 'dormitory': 2, 'stimulate': 2, 'piece': 2, 'bend': 2, 'hat': 2, 'onward': 2, 'operate': 2, 'acknowledge': 2, 'explane': 2, 'fantasize': 2, 'was': 2, 'peeve': 2, 'act': 2, 'collect': 2, 'umm': 2, 'reccomend': 2, 'akind': 2, 'seek': 2, 'drinks': 2, 'rest': 2, 'select': 2, 'complexly': 2, 'review': 2, 'x': 2, 'colour': 2, 'tea': 2, 'answer': 2, 'test': 2, 'explain': 2, 'tallk': 2, 'athlete': 2, 'arise': 2, 'achieve': 2, 'rememberd': 2, 'verb': 2, 'warmly': 2, 'haven': 2, 'bcause': 2, 'behave': 2, 'fatal': 2, 'embrace': 2, 'warehouse': 2, 'de': 2, 'hon': 2, 'burnt': 2, 'present': 2, 'korean': 2, 'bless': 2, 'color': 2, 'clean': 2, 'froze': 2, 'tap': 2, 'ready': 2, 'control': 2, 'possess': 2, 'podcast': 2, 'closest': 2, 'url': 2, 'deliberate': 2, 'wiht': 2, 'zhout': 2, 'spoke': 2, 'whilst': 2, 'dear': 2, 'beacuse': 2, 'helps': 2, 'whole': 2, 'overeat': 2, 'crazy': 2, 'rank': 2, 'looks': 2, 'concave': 2, 'fry': 2, 'associate': 2, 'focus': 2, 'truethat': 2, 'tool': 2, 'afterwards': 2, 'stammer': 2, 'evaluate': 2, 'depart': 2, 'okay': 2, 'claim': 2, 'hesitate': 2, 'mend': 2, 'challenge': 2, 'train': 2, 'laid': 2, 'chew': 2, 'cold': 2, 'fight': 2, 'stole': 2, 'exist': 2, 'regulary': 2, 'truly': 2, 'alway': 2, 'calm': 2, 'remain': 2, 'dylan': 2, 'brave': 2, 'abuse': 2, 'settle': 2, 'knew': 2, 'ourself': 2, 'atyang': 2, 'fromit': 2, 'consult': 2, 'didint': 2, 'advise': 2, 'fiind': 2, 'peak': 2, 'deal': 2, 'hade': 2, 'enterd': 2, 'knowledge': 2, 'recomend': 2, 'mystery': 2, 'sometimes': 2, 'risk': 2, 'didn': 2, 'haha': 2, 'oh': 2, 'sincerely': 2, 'outweigh': 2, 'export': 2, 'aguess': 2, 'ignore': 2, 'dine': 2, 'wash': 2, 'donno': 2, 'locatid': 2, 'accidentallyfound': 2, 'arrivehome': 2, 'appeal': 2, 'silent': 2, 'view': 2, 'mother': 2, 'teru': 2, 'containstolen': 2, 'postpone': 2, 'stir': 2, 'own': 2, 'thumb': 2, 'owe': 2, 'nature': 2, 'fiestas': 2, 'mistaken': 2, 'fourth': 2, 'limit': 2, 'anymore': 2, 'tomorow': 2, 'sharpen': 2, 'observe': 2, 'consume': 2, 'nooo': 2, 'gggot': 2, \"'sss\": 2, 'alreeeady': 2, 'wroteee': 2, 'forward': 2, 'forgotten': 2, 'wrottte': 2, 'translate': 2, 'trieddd': 2, 'whhhile': 2, 'afttter': 2, 'hereee': 2, 'feeelt': 2, 'manageddd': 2, 'gavvve': 2, 'offff': 2, 'playeddd': 2, 'gotten': 2, 'alllthough': 2, 'starteeed': 2, 'weeell': 2, 'sooome': 2, 'eeevery': 2, 'lang': 2, 'boss': 2, 'ppplayed': 2, 'wwwrote': 2, 'yeserday': 2, 'weather': 2, 'impatient': 2, 'memorize': 2, 'shouldnt': 2, 'arriveddd': 2, 'spennnt': 2, 'overtime': 2, 'washeeed': 2, 'club': 2, 'upset': 2, 'ssseen': 2, 'cookeddd': 2, 'evvvery': 2, 'sushi': 2, 'overrr': 2, 'extend': 2, 'stiiill': 2, 'emigrate': 2, 'expensive': 2, 'mmmet': 2, 'rrread': 2, 'rude': 2, 'bbbefore': 2, 'bottth': 2, 'becccame': 2, 'hhhere': 2, 'pull': 2, 'heeeard': 2, 'hhheard': 2, 'cave': 2, 'bore': 2, 'wellll': 2, 'free': 2, 'anooother': 2, 'ohhh': 2, 'bbbeen': 2, 'eveeen': 2, 'wrooote': 2, 'aaany': 2, 'justtt': 2, 'alllmost': 2, 'pain': 2, 'ovvver': 2, 'awesome': 2, 'boooth': 2, 'stand': 2, 'eachhh': 2, 'sari': 2, 'bbboth': 2, 'baaack': 2, 'alwaysss': 2, 'chicken': 2, 'ttthrough': 2, 'asleep': 2, 'everyyy': 2, 'feed': 2, 'marry': 2, 'thhhrough': 2, 'askeddd': 2, 'neeear': 2, 'leffft': 2, 'sinccce': 2, 'sad': 2, 'ta': 2, 'sure': 2, 'learning': 2, 'thoughttt': 2, 'lefttt': 2, 'overcome': 2, 'amid': 2, 'nnnever': 2, 'thhhan': 2, 'wokkke': 2, 'sumo': 2, 'beeegan': 2, 'iiif': 2, 'muchhh': 2, 'gaaave': 2, 'design': 2, 'upooon': 2, 'becaussse': 2, 'ofteeen': 2, 'ofttten': 2, 'sometimeees': 2, 'angry': 2, 'becaaame': 2, 'enough': 2, 'herrre': 2, 'imitate': 2, 'alone': 2, 'connect': 2, 'ssspent': 2, 'thhhis': 2, 'alwaaays': 2, 'built': 2, 'alooong': 2, 'onccce': 2, 'reallyyy': 2, 'wiiithout': 2, 'aaalways': 2, 'passeddd': 2, 'joineeed': 2, 'easy': 2, 'visiteeed': 2, 'arooound': 2, 'ttthere': 2, 'likeee': 2, 'driven': 2, 'sentence': 2, 'anywayyy': 2, 'thouuugh': 2, 'type': 2, 'oveeer': 2, 'thiiis': 2, 'nice': 2, 'everrr': 2, 'regard': 2, 'tread': 2, 'cover': 2, 'likkke': 2, 'em': 1, 'loves': 1, 'listend': 1, 'shoot': 1, 'pour': 1, 'scratch': 1, 'argue': 1, 'relace': 1, 'realy': 1, 'interviewer': 1, 'propose': 1, 'mostley': 1, 'worte': 1, 'squat': 1, 'bacause': 1, 'update': 1, 'ash': 1, 'worse': 1, 'rock': 1, 'hiphop': 1, 'land': 1, 'willdriveyou': 1, 'daresay': 1, 'happiness': 1, 'apply': 1, 'ocean': 1, 'figure': 1, 'yes': 1, 'versus': 1, 'indirect': 1, 'anxious': 1, 'usualy': 1, 'discuss': 1, 'akipponn': 1, 'form': 1, 'diary': 1, 'got': 1, 'grateful': 1, 'canhelp': 1, 'ha': 1, 'mada': 1, 'bugger': 1, 'origin': 1, 'insert': 1, 'agreed': 1, 'okra': 1, 'isin': 1, 'bear': 1, 'kkk': 1, 'aren': 1, 'occupy': 1, 'tall': 1, 'turnedaround': 1, 'accede': 1, 'wo': 1, 'contain': 1, 'yay': 1, 'envelope': 1, 'selfish': 1, 'wherein': 1, 'drool': 1, 'sacrifice': 1, 'ah': 1, 'thrive': 1, 'havebecome': 1, 'lend': 1, 'thisto': 1, 'cross': 1, 'sooooooooooooo': 1, 'refrain': 1, 'phobic': 1, 'prayed': 1, 'sung': 1, 'strive': 1, 'plaed': 1, 'viewof': 1, 'conduct': 1, 'waffle': 1, 'shorten': 1, 'hurry': 1, 'wow': 1, 'cultivate': 1, 'could': 1, 'mustmaintain': 1, 'appriciate': 1, 'bye': 1, 'aneguet': 1, 'became': 1, 'agreewith': 1, 'stroll': 1, 'swelter': 1, 'pratice': 1, 'havenever': 1, 'boyfriend': 1, 'describe': 1, 'flowershave': 1, 'teste': 1, 'excuse': 1, 'pmand': 1, 'reread': 1, 'surfed': 1, 'affect': 1, 'yomimasen': 1, 'kara': 1, 'reject': 1, 'everybody': 1, 'shame': 1, 'g': 1, 'jot': 1, 'hid': 1, 'soooo': 1, 'enrich': 1, 'aber': 1, 'j': 1, 'offen': 1, 'dress': 1, 'ps': 1, 'repliedtoher': 1, 'contend': 1, 'rub': 1, 'gye': 1, 'beenvery': 1, 'sax': 1, 'misunderstood': 1, 'beause': 1, 'praise': 1, 'kkkkk': 1, 'tommorow': 1, 'release': 1, 'assemble': 1, 'neurosurgery': 1, 'berry': 1, 'becasue': 1, 'but': 1, 'tikyu': 1, 'ihave': 1, 'working': 1, 'cram': 1, 'osechi': 1, 'kidding': 1, 'luck': 1, 'skateboad': 1, 'ache': 1, 'stifle': 1, 'cool': 1, 'retreat': 1, 'well': 1, 'paraphrase': 1, 'attitude': 1, 'playing': 1, 'disappear': 1, 'deciede': 1, 'specialize': 1, 'grasp': 1, 'adjust': 1, 'conceal': 1, 'inspire': 1, 'indulge': 1, 'wll': 1, 'reach': 1, 'whoever': 1, 'superficial': 1, 'differ': 1, 'shoule': 1, 'pw': 1, 'wished': 1, 'blind': 1, 'despise': 1, 'tube': 1, 'dvd': 1, 'shop': 1, 'finaly': 1, 'paint': 1, 'resolve': 1, 'sign': 1, 'dance': 1, 'omgsh': 1, 'confident': 1, 'volleyball': 1, 'sweat': 1, 'yea': 1, 'attract': 1, 'itake': 1, 'cope': 1, 'warn': 1, 'obstructing': 1, 'experence': 1, 'ike': 1, 'uset': 1, 'warm': 1, 'surround': 1, 'were': 1, 'shouldread': 1, 'hearthe': 1, 'dedicate': 1, 'butterfly': 1, 'financialy': 1, 'dirty': 1, 'proceed': 1, 'introduction': 1, 'disturb': 1, 'hurts': 1, 'attempt': 1, 'standardize': 1, 'survive': 1, 'iike': 1, 'asian': 1, 'liqueur': 1, 'bow': 1, 'weretoo': 1, 'hustle': 1, 'becamelost': 1, 'cancel': 1, 'rainy': 1, 'thinhk': 1, 'cause': 1, 'identify': 1, 'coud': 1, 'decid': 1, 'rise': 1, 'velify': 1, 'tutor': 1, 'sunshine': 1, 'nowwe': 1, 'omg': 1, 'mail': 1, 'accompany': 1, 'oneday': 1, 'insult': 1, 'dyed': 1, 'blame': 1, 'steppedon': 1, 'fellinto': 1, 'beforehand': 1, 'divide': 1, 'soooooooooooo': 1, 'part': 1, 'online': 1, 'havee': 1, 'canbe': 1, 'came': 1, 'bribe': 1, 'sore': 1, 'pluck': 1, 'amazon': 1, 'nagging': 1, 'brake': 1, 'avoid': 1, 'twelve': 1, 'wouldnt': 1, 'recieve': 1, 'guide': 1, 'mine': 1, 'funny': 1, 'gott': 1, 'hav': 1, 'lean': 1, 'e': 1, 'fold': 1, 'def': 1, 'experience': 1, 'blew': 1, 'okonomiyaki': 1, 'heavy': 1, 'web': 1, 'triedto': 1, 'reccommend': 1, 'indicate': 1, 'penny': 1, 'comfirm': 1, 'numpty': 1, 'willread': 1, 'convene': 1, 'drip': 1, 'atthat': 1, 'nevertheless': 1, 'background': 1, 'talkeddd': 1, 'drooove': 1, 'alopecia': 1, 'calleeed': 1, 'steppeddd': 1, 'geve': 1, 'theseee': 1, 'couldnt': 1, 'ammmong': 1, 'gottheiphone': 1, 'reaaad': 1, 'twiceee': 1, 'wwwell': 1, 'prepareddd': 1, 'betweeeen': 1, 'affiliate': 1, 'speakkorean': 1, 'scareeed': 1, 'realizedyou': 1, 'stick': 1, 'sense': 1, 'works': 1, 'faileddd': 1, 'spit': 1, 'orlando': 1, 'asthma': 1, 'fffirst': 1, 'step': 1, 'againnnst': 1, 'strawberry': 1, 'slepppt': 1, 'pokemon': 1, 'exxxcept': 1, 'sorroweddd': 1, 'aaanother': 1, 'ham': 1, 'awayyy': 1, 'trulyyy': 1, 'snore': 1, 'marrieeed': 1, 'picture': 1, 'tossss': 1, 'baccck': 1, 'workeeed': 1, 'pink': 1, 'tore': 1, 'aaabove': 1, 'cannt': 1, 'nervous': 1, 'eveeery': 1, 'remembereeed': 1, 'enugh': 1, 'faileeed': 1, 'withhhout': 1, 'nap': 1, 'cafe': 1, 'comprehend': 1, 'shave': 1, 'likeddd': 1, 'cleand': 1, 'havent': 1, 'photos': 1, 'akihabara': 1, 'grown': 1, 'extra': 1, 'maintain': 1, 'laaaugh': 1, 'togettther': 1, 'okaaay': 1, 'applieeed': 1, 'steep': 1, 'react': 1, 'sssaw': 1, 'entereeed': 1, 'emit': 1, 'ouuut': 1, 'loveeed': 1, 'beeeacuse': 1, 'feeell': 1, 'jump': 1, 'passeeed': 1, 'althooough': 1, 'norsk': 1, 'learneddd': 1, 'tv': 1, 'outsiiide': 1, 'grilleeed': 1, 'counteddd': 1, 'speaks': 1, 'roameeed': 1, 'cookeeed': 1, 'jhon': 1, 'guideeed': 1, 'handball': 1, 'cheesy': 1, 'wrap': 1, 'becauseee': 1, 'video': 1, 'okinawa': 1, 'backkk': 1, 'fallen': 1, 'hasss': 1, 'known': 1, 'througgghout': 1, 'um': 1, 'starts': 1, 'nowadaaays': 1, 'nexxxt': 1, 'bird': 1, 'registereddd': 1, 'chase': 1, 'stung': 1, 'tequila': 1, 'rd': 1, 'thereupon': 1, 'aaalongside': 1, 'soundsss': 1, 'genius': 1, 'dinner': 1, 'pronouce': 1, 'originate': 1, 'hunggg': 1, 'helpful': 1, 'sensitive': 1, 'square': 1, 'studieddd': 1, 'thirsty': 1, 'transmit': 1, 'caught': 1, 'heaaard': 1, 'stays': 1, 'arrang': 1, 'aaafter': 1, 'elmo': 1, 'wine': 1, 'hill': 1, 'high': 1, 'lit': 1, 'ointment': 1, 'exams': 1, 'seeent': 1, 'luuunch': 1, 'wanttts': 1, 'afterrr': 1, 'wonnn': 1, 'enjoooyed': 1, 'richer': 1, 'twenty': 1, 'thinkingabout': 1, 'pov': 1, 'annnother': 1, 'chosen': 1, 'saaaid': 1, 'bornnn': 1, 'sssent': 1, 'raaan': 1, 'buckle': 1, 'flag': 1, 'someee': 1, 'youtube': 1, 'curious': 1, 'gaveee': 1, 'cafes': 1, 'starterd': 1, 'evvver': 1, 'concide': 1, 'awaaay': 1, 'sho': 1, 'anothhher': 1, 'enjoyeeed': 1, 'na': 1, 'gathereeed': 1, 'maybe': 1, 'betweennn': 1, 'abooove': 1, 'caughhht': 1, 'wiil': 1, 'toeic': 1, 'afraiddd': 1, 'envious': 1, 'ill': 1, 'offften': 1, 'playyyed': 1, 'spokeee': 1, 'agaaainst': 1, 'soooon': 1, 'hadnt': 1, 'prohibit': 1, 'neveeer': 1, 'incorrect': 1, 'moveeed': 1, 'aaalthough': 1, 'continueeed': 1, 'smart': 1, 'confirmeddd': 1, 'goose': 1, 'fourteen': 1, 'driveeed': 1, 'alwwways': 1, 'safe': 1, 'yuan': 1, 'thusss': 1, 'regreteeed': 1, 'inttto': 1, 'illuminate': 1, 'enchiladas': 1, 'produce': 1, 'traveleeed': 1, 'cleaneeed': 1, 'vacuum': 1, 'kepppt': 1, 'norrr': 1, 'cut': 1, 'suffocate': 1, 'wakes': 1, 'ttthen': 1, 'brings': 1, 'images': 1, 'junior': 1, 'returneddd': 1, 'swim': 1, 'wrrrote': 1, 'most': 1, 'hellld': 1, 'insomnia': 1, 'ear': 1, 'language': 1, 'seaweed': 1, 'lookeddd': 1, 'dddown': 1, 'painting': 1, 'arounnnd': 1, 'tolddd': 1, 'brrread': 1, 'soup': 1, 'sake': 1, 'sommmetimes': 1, 'afteeer': 1, 'pretty': 1, 'muccch': 1, 'sollld': 1, 'rivaleddd': 1, 'mus': 1, 'flown': 1, 'equip': 1, 'wwwore': 1, 'involve': 1, 'attach': 1, 'notmet': 1, 'restaurant': 1, 'policeman': 1, 'firssst': 1, 'cooold': 1, 'mysterrry': 1, 'ohanami': 1, 'startto': 1, 'busier': 1, 'torussia': 1, 'theni': 1, 'beeefore': 1, 'anottther': 1, 'cute': 1, 'towwward': 1, 'booo': 1, 'yettt': 1, 'motivate': 1, 'beaten': 1, 'talkeeed': 1, 'sssaid': 1, 'trails': 1, 'beat': 1, 'stayeeed': 1, 'shiitake': 1, 'overcame': 1, 'vary': 1, 'ofrainy': 1, 'speeent': 1, 'karaoke': 1, 'noticeddd': 1, 'han': 1, 'octopus': 1, 'moreovvver': 1, 'understooddd': 1, 'distinguish': 1, 'mistake': 1, 'totallyyy': 1, 'late': 1, 'reeead': 1, 'horror': 1, 'envys': 1, 'delicious': 1, 'tttold': 1, 'becameee': 1, 'teaseeed': 1, 'shot': 1, 'harvest': 1, 'levttown': 1, 'inherit': 1, 'deliver': 1, 'decideeed': 1, 'ssstill': 1, 'cheesecake': 1, 'surviveeed': 1, 'befooore': 1, 'thannn': 1, 'beeecame': 1, 'draaank': 1, 'sssat': 1, 'hearddd': 1, 'method': 1, 'cleaning': 1, 'dissolve': 1, 'askesd': 1, 'barbecue': 1, 'bbbroken': 1, 'sssang': 1, 'adopteddd': 1, 'innnto': 1, 'ennnough': 1, 'alreadddy': 1, 'sakura': 1, 'beautiful': 1, 'paaaid': 1, 'fooorgotten': 1, 'laughhhed': 1, 'gad': 1, 'bleach': 1, 'missjohn': 1, 'beeehind': 1, 'sidewalk': 1, 'becase': 1, 'dddrew': 1, 'cheap': 1, 'fffast': 1, 'beggeddd': 1, 'open': 1, 'samurai': 1, 'hardlyyy': 1, 'downnn': 1, 'massages': 1, 'climb': 1, 'eithhher': 1, 'untiiil': 1, 'probabbbly': 1, 'therrre': 1, 'extremelyyy': 1, 'anesthesia': 1, 'throughhh': 1, 'cup': 1, 'preach': 1, 'wrrritten': 1, 'fix': 1, 'thoght': 1, 'theeerefore': 1, 'arab': 1, 'concert': 1, 'nnnear': 1, 'surprise': 1, 'cynical': 1, 'besidesss': 1, 'slip': 1, 'irori': 1, 'viaaa': 1, 'somehow': 1, 'xbox': 1, 'thhherefore': 1, 'conducteeed': 1, 'omlets': 1, 'novel': 1, 'alrrready': 1, 'boild': 1, 'patrias': 1, 'alive': 1, 'thooough': 1, 'nearrr': 1, 'quiteee': 1, 'anxiety': 1, 'recordeeed': 1, 'horns': 1, 'revise': 1, 'althhhough': 1, 'drowsy': 1, 'uuunder': 1, 'forgooot': 1, 'asked': 1, 'congratuate': 1, 'unddder': 1, 'nise': 1, 'soo': 1, 'quote': 1, 'receiveeed': 1, 'laugggh': 1, 'confuse': 1, 'sometimesss': 1, 'pod': 1, 'pricey': 1, 'chatteeed': 1, 'learnd': 1, 'seldooom': 1, 'encounter': 1, 'stackeddd': 1, 'adzuki': 1, 'ppper': 1, 'wet': 1, 'excccept': 1, 'lossst': 1, 'awhile': 1, 'super': 1, 'spendingyour': 1, 'stuff': 1, 'neeext': 1, 'warmmm': 1, 'listeneeed': 1, 'revealeeed': 1, 'puttt': 1, 'nnnot': 1, 'amsame': 1, 'blue': 1, 'respondeddd': 1, 'fresh': 1, 'eikaiwa': 1, 'conflict': 1, 'petty': 1, 'seven': 1, 'delete': 1, 'means': 1, 'zombie': 1, 'mid': 1, 'inssstead': 1, 'girlfriend': 1, 'taht': 1, 'waltz': 1, 'hmm': 1, 'cinema': 1, 'supposeeed': 1, 'consist': 1, 'goint': 1, 'haaas': 1, 'wwwhile': 1, 'studiedenglish': 1, 'woken': 1, 'thereee': 1, 'innocent': 1, 'neeearby': 1, 'increase': 1, 'h': 1, 'fine': 1, 'ooover': 1, 'eager': 1, 'viiisit': 1, 'someeetimes': 1, 'finisheddd': 1, 'becouse': 1, 'firmlyyy': 1, 'tastedwell': 1, 'blackout': 1, 'tolerant': 1, 'amooong': 1, 'useddd': 1, 'compliment': 1, 'art': 1, 'rip': 1, 'ooonto': 1, 'nbsp': 1, 'eric': 1, 'volunteer': 1, 'attendeeed': 1, 'download': 1, 'subtitle': 1, 'bothhh': 1, 'arounddd': 1, 'veee': 1, 'android': 1, 'hiro': 1, 'migraine': 1, 'expensivefor': 1, 'separate': 1, 'barelyyy': 1, 'cjs': 1, 'duet': 1, 'heehee': 1, 'cm': 1, 'predict': 1, 'yao': 1, 'skype': 1, 'callthis': 1, 'smoker': 1, 'threw': 1, 'okayama': 1, 'graham': 1, 'donnne': 1, 'underneath': 1, 'ouuutside': 1, 'whillle': 1, 'expecteddd': 1, 'cammme': 1, 'otaku': 1, 'fur': 1, 'clothes': 1, 'througggh': 1, 'theeen': 1, 'sommme': 1, 'emotional': 1, 'noodle': 1, 'eeexcept': 1, 'maroon': 1, 'assess': 1, 'note': 1, 'hotcake': 1, 'withooout': 1, 'thailand': 1, 'ridden': 1, 'planteeed': 1, 'leeeft': 1, 'mixed': 1, 'wriiitten': 1, 'mooore': 1, 'earthquakes': 1, 'processeeed': 1, 'aaagain': 1, 'underrr': 1, 'spenttt': 1, 'thaaan': 1, 'honer': 1, 'agaiiin': 1, 'vcds': 1, 'concur': 1, 'lateeer': 1, 'oooff': 1, 'aaare': 1, 'normaly': 1, 'lineddd': 1, 'speech': 1, 'awoke': 1, 'remenbereddd': 1, 'wassshlet': 1, 'beforrre': 1, 'escape': 1, 'candy': 1, 'halloween': 1, 'fed': 1, 'interior': 1, 'checkeeed': 1, 'neaaar': 1, 'nz': 1, 'anexam': 1, 'thatnicotinell': 1, 'sea': 1, 'sweet': 1, 'cleaneddd': 1, 'advertise': 1, 'kkknew': 1, 'command': 1, 'lllol': 1, 'navy': 1, 'gathereddd': 1, 'coffee': 1, 'eeever': 1, 'uuuntil': 1, 'hhheld': 1, 'jugon': 1, 'headeddd': 1, 'openeddd': 1, 'nowww': 1, 'sometimmmes': 1, 'turneeed': 1, 'begaaan': 1, 'becammme': 1, 'everyone': 1, 'borroweeed': 1, 'practiceddd': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG5_bCSm-59X",
        "outputId": "9bcdb458-30ba-4561-ad1f-5b68cb7e16ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def tokenize(vocab,sentences):\n",
        "    temp = {}\n",
        "    for w,freq in (vocab.items()):\n",
        "        if(freq > 2):\n",
        "            temp[w] = freq\n",
        "        \n",
        "                    \n",
        "    vocab = temp\n",
        "    vocab_to_int = {word: ii for ii, word in enumerate(vocab, 2)} #reserving one for unknown\n",
        "    vocab_to_int['unk'] = 1\n",
        "    dataset_int = []\n",
        "    for sent in sentences:\n",
        "        #print(sent)\n",
        "        sentSeq = []\n",
        "        for word in sent.split():\n",
        "            if word in vocab_to_int:\n",
        "                sentSeq.append(vocab_to_int[word])\n",
        "            else:\n",
        "                sentSeq.append(vocab_to_int['unk'])\n",
        "        #print(sentSeq)\n",
        "        dataset_int.append(sentSeq)\n",
        "    return dataset_int,vocab_to_int\n",
        "\n",
        "text_tokenized, text_tokenizer = tokenize(words_counter,trainSet[:,0])\n",
        "print(text_tokenizer)\n",
        "print('Count tokens:', len(text_tokenizer))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prp': 2, 'i': 3, 'vbd': 4, 'jj': 5, 'cc': 6, 'to': 7, 'vb': 8, 'nns': 9, 'rb': 10, 'nn': 11, 'innn': 12, 'before': 13, 'dt': 14, 'this': 15, ',': 16, 'vbp': 17, 'think': 18, 'am': 19, 'vbg': 20, 'on': 21, 'a': 22, 'P': 23, 'as': 24, 'B': 25, 'jjr': 26, 'have': 27, 'vbn': 28, 'md': 29, 'about': 30, 'prpd': 31, 'my': 32, 'pos': 33, 'it': 34, 'you': 35, 'nnp': 36, 'uh': 37, 'rp': 38, 'for': 39, 'the': 40, 'your': 41, 'because': 42, 'we': 43, 'like': 44, 'with': 45, 'so': 46, 'are': 47, 'vbz': 48, 'than': 49, 'K': 50, 'them': 51, 'that': 52, 'wrb': 53, 'our': 54, 'F': 55, 'after': 56, 'sleep': 57, 'until': 58, 'in': 59, 'me': 60, 'of': 61, 'he': 62, 'she': 63, 'they': 64, 'live': 65, 'ex': 66, 'if': 67, 'want': 68, 'find': 69, 'any': 70, 'cd': 71, 'by': 72, 'L': 73, 'wdt': 74, 'take': 75, 'R': 76, 'hope': 77, '``': 78, 'every': 79, 'some': 80, 'H': 81, 'both': 82, 'N': 83, 'seldom': 84, 'S': 85, 'say': 86, 'make': 87, 'come': 88, 'use': 89, 'need': 90, 'from': 91, 'while': 92, 'please': 93, 'jjs': 94, 'himself': 95, 'read': 96, 'wp': 97, 'G': 98, 'yen': 99, 'over': 100, 'miss': 101, 'do': 102, 'whether': 103, 'feel': 104, 'an': 105, 'I': 106, 'between': 107, 'no': 108, 'seem': 109, 'drank': 110, 'wish': 111, 'W': 112, 'her': 113, 'all': 114, 'A': 115, 'nnps': 116, 'T': 117, 'at': 118, 'work': 119, 'rbs': 120, 'start': 121, 'into': 122, 'D': 123, 'per': 124, 'love': 125, 'V': 126, 'go': 127, 'myself': 128, 'forget': 129, 'upon': 130, 'his': 131, 'worry': 132, 'understand': 133, 'him': 134, 'imagine': 135, 'though': 136, 'their': 137, 'swam': 138, 'good': 139, 'know': 140, 'rbr': 141, 'these': 142, 'back': 143, 'those': 144, 'respect': 145, 'get': 146, 'without': 147, 'during': 148, 'fail': 149, 'around': 150, 'another': 151, 'J': 152, 'pdt': 153, 'dont': 154, 'above': 155, 'us': 156, 'spilt': 157, 'forgot': 158, 'via': 159, 'each': 160, 'although': 161, 'either': 162, 'm': 163, 'prefer': 164, 'play': 165, 'since': 166, 'digit': 167, 'learn': 168, 'let': 169, 'cook': 170, 'wonder': 171, 'lol': 172, 'M': 173, 'felt': 174, 'quit': 175, 'desire': 176, 'guys': 177, 'call': 178, 'study': 179, 'wan': 180, 'finish': 181, 'out': 182, 'C': 183, 'try': 184, 'through': 185, 'belive': 186, 'E': 187, 'ate': 188, 'admit': 189, 'fly': 190, 'under': 191, 'hurt': 192, 'hear': 193, 'its': 194, 'write': 195, 'see': 196, 'hahaha': 197, 'n': 198, 'll': 199, 'help': 200, 'wear': 201, 'past': 202, 'disagree': 203, 'run': 204, 'among': 205, 'listen': 206, 'meet': 207, 'against': 208, 'surf': 209, 'hate': 210, 'within': 211, 'friend': 212, 'meant': 213, 'sit': 214, 'decide': 215, 'pray': 216, 'off': 217, 'dreamt': 218, 'enjoy': 219, 'keep': 220, 'correct': 221, 'remember': 222, 'grow': 223, 'travel': 224, 'admire': 225, 'fw': 226, 'except': 227, 'ago': 228, 'change': 229, 'eat': 230, 'yourself': 231, 'believe': 232, 'up': 233, 'understood': 234, 'watch': 235, 'themselves': 236, 'enjoyed': 237, 'near': 238, 'beside': 239, 'speak': 240, 'appreciate': 241, 'provide': 242, 'expect': 243, 'drive': 244, 'recommend': 245, 'spread': 246, 'tell': 247, 'thought': 248, 'join': 249, 'close': 250, 'teach': 251, 'didnt': 252, 'swear': 253, 'ride': 254, 'promise': 255, 'inside': 256, 'visit': 257, 'Y': 258, 'drink': 259, 'look': 260, 'suggest': 261, 'outside': 262, 'happend': 263, 'along': 264, 'give': 265, 'jog': 266, 'exercise': 267, 'guess': 268, 'O': 269, 'don': 270, 'cheer': 271, 'spend': 272, 'cant': 273, 'despite': 274, 'slept': 275, 'contest': 276, 'mean': 277, 'itself': 278, 'upload': 279, 'create': 280, 'stop': 281, 'lose': 282, 'laugh': 283, 'everyday': 284, 'belong': 285, 'oneself': 286, 'hit': 287, 'stayed': 288, 'curry': 289, 'touch': 290, 'educate': 291, 'follow': 292, 'put': 293, 'leave': 294, 'insist': 295, 'become': 296, 'wake': 297, 'broth': 298, 'introduce': 299, 'likedthem': 300, 'record': 301, 'lack': 302, 'toward': 303, 'talk': 304, 'pass': 305, 'd': 306, 'trust': 307, 'besides': 308, 'check': 309, 'across': 310, 'next': 311, 'transcribe': 312, 'ls': 313, 'went': 314, \"''\": 315, 'arrive': 316, 'snow': 317, \"'s\": 318, 'xd': 319, 'wait': 320, 'bit': 321, 'plan': 322, 've': 323, 'perform': 324, 'draw': 325, 'learnt': 326, 'buy': 327, 'gon': 328, 'dare': 329, 'taught': 330, 'bring': 331, 'intend': 332, 'stay': 333, 'drunk': 334, 'criticize': 335, 'b': 336, 'suppose': 337, 'herself': 338, 'agree': 339, 'earn': 340, 'express': 341, 'overslept': 342, 'appear': 343, 'turn': 344, 'depend': 345, 'deeply': 346, 'below': 347, 'roll': 348, 'envy': 349, '$': 350, 'very': 351, 'self': 352, 'require': 353, 'Z': 354, 're': 355, 'heard': 356, 'eaten': 357, 'attend': 358, 'relaxed': 359, 'add': 360, 'walk': 361, 'chose': 362, 'enter': 363, 'happen': 364, 'fall': 365, 't': 366, 'deserve': 367, 'realize': 368, 'continue': 369, 'gather': 370, 'hold': 371, 'regret': 372, 'lake': 373, 'consider': 374, 'pay': 375, 'die': 376, 'unlike': 377, 'rely': 378, 'rebuilt': 379, 'someday': 380, 'assume': 381, 'receive': 382, 'choose': 383, 'ok': 384, 'begin': 385, 'return': 386, 'rode': 387, 'chat': 388, 'throughout': 389, 'ran': 390, 'sang': 391, 'behind': 392, 'welcome': 393, \"'cause\": 394, 'annoy': 395, 'suffer': 396, 'offer': 397, 'communicate': 398, 'prepare': 399, 'relax': 400, 'move': 401, 'care': 402, 'unless': 403, 'license': 404, 'graduate': 405, 'face': 406, 'nowadays': 407, 'tend': 408, 'search': 409, 'quarrel': 410, 'ourselves': 411, 'bid': 412, 'commute': 413, 'doubt': 414, 'carry': 415, 'complain': 416, 'played': 417, 'teacher': 418, 'worth': 419, 'discover': 420, 'celebrate': 421, 'dislike': 422, 'beyond': 423, 'concentrate': 424, 'bet': 425, 's': 426, 'sound': 427, 'taste': 428, 'onto': 429, 'gain': 430, 'save': 431, 'show': 432, 'drop': 433, 'sell': 434, 'hard': 435, 'wave': 436, 'fit': 437, 'th': 438, 'rice': 439, 'cry': 440, 'wore': 441, 'ask': 442, 'sing': 443, 'hung': 444, 'end': 445, 'catch': 446, 'throw': 447, 'accept': 448, 'bite': 449, 'treat': 450, 'report': 451, 'set': 452, 'brush': 453, 'notice': 454, 'soak': 455, 'japanese': 456, 'dream': 457, 'born': 458, 'pm': 459, 'couldn': 460, 'shoud': 461, 'apologize': 462, 'neither': 463, 'encourage': 464, 'therefore': 465, 'o': 466, 'participate': 467, 'better': 468, 'essay': 469, 'little': 470, 'waste': 471, 'down': 472, 'sneeze': 473, 'nead': 474, 'wherever': 475, 'sooo': 476, 'send': 477, 'click': 478, 'u': 479, 'shower': 480, 'p': 481, 'fel': 482, 'once': 483, 'w': 484, 'soccer': 485, 'pick': 486, 'recognize': 487, 'rain': 488, 'spent': 489, 'ume': 490, 'contribute': 491, 'question': 492, 'represent': 493, 'cherry': 494, 'eve': 495, 'proud': 496, 'occur': 497, 'log': 498, 'post': 499, 'match': 500, 'which': 501, 'degree': 502, 'thank': 503, 'hair': 504, 'anytime': 505, 'mind': 506, 'handle': 507, 'greet': 508, 'solve': 509, 'l': 510, 'support': 511, 'elect': 512, 'afraid': 513, 'spray': 514, 'break': 515, 'glad': 516, 'comment': 517, 'serve': 518, 'permit': 519, 'adore': 520, 'ya': 521, 'sick': 522, 'cough': 523, 'matsutake': 524, 'splash': 525, 'wrong': 526, 'till': 527, 'ten': 528, 'mistook': 529, 'towards': 530, 'spicy': 531, 'whenever': 532, 'aim': 533, 'strange': 534, 'sleepy': 535, 'smell': 536, 'sym': 537, 'win': 538, 'haaad': 539, 'gottt': 540, 'aaa': 541, 'wenttt': 542, 'annnd': 543, 'aaabout': 544, 'aaand': 545, 'fellll': 546, 'buttt': 547, 'diiid': 548, 'thhhat': 549, 'brown': 550, 'ssso': 551, 'founddd': 552, 'dddid': 553, 'wennnt': 554, 'iiin': 555, 'wasss': 556, 'forrr': 557, 'fun': 558, 'haddd': 559, 'saiddd': 560, 'fooor': 561, 'weeent': 562, 'refuse': 563, 'uuup': 564, 'abbbout': 565, 'wereee': 566, 'waaas': 567, 'liiike': 568, 'madeee': 569, 'ooof': 570, 'felllt': 571, 'offf': 572, 'frrrom': 573, 'abouttt': 574, 'wwwas': 575, 'abooout': 576, 'ttthat': 577, 'byyy': 578, 'busy': 579, 'tookkk': 580, 'tooook': 581, 'jjjust': 582, 'knewww': 583, 'aaat': 584, 'useeed': 585, 'thaaat': 586, 'becccause': 587, 'alssso': 588, 'isss': 589, 'sorry': 590, 'juuust': 591, 'thoughhht': 592, 'arrround': 593, 'anddd': 594, 'meeet': 595, 'onnn': 596, 'thousand': 597, 'agggo': 598, 'oooften': 599, 'buuut': 600, 'thisss': 601, 'ttthe': 602, 'iiis': 603, 'friends': 604, 'weeere': 605, 'wwwith': 606, 'fffor': 607, 'maaade': 608, 'caaame': 609, 'orrr': 610, 'thattt': 611, 'aaaround': 612, 'beeecause': 613, 'aaas': 614, 'becauuuse': 615, 'improve': 616, 'tt': 617, 'everrry': 618, 'bbbecause': 619, 'ttthis': 620, 'hungry': 621, 'begggan': 622, 'diddd': 623, 'fouuund': 624, 'hhhas': 625, 'display': 626, 'ooon': 627, 'ooor': 628, 'aaall': 629, 'felttt': 630, 'tollld': 631, 'stillll': 632, 'jussst': 633, 'wiiith': 634, 'abouuut': 635, 'withhh': 636, 'thhhe': 637, 'aaan': 638, 'arouuund': 639, 'thrrrough': 640, 'mmmade': 641, 'fffrom': 642, 'gooot': 643, 'founnnd': 644, 'aaalso': 645, 'attt': 646, 'trieeed': 647, 'rent': 648, 'fffelt': 649, 'cameee': 650, 'wwwent': 651, 'stttill': 652, \"'t\": 653, 'wwwere': 654, 'cccame': 655, 'sawww': 656, 'nooot': 657, 'lllike': 658, 'boughhht': 659, 'ppput': 660, 'watcheddd': 661, 'askeeed': 662, 'english': 663, 'usuallyyy': 664, 'thhhough': 665, 'wittth': 666, 'werrre': 667, 'fooound': 668, 'alllso': 669, 'boughttt': 670, 'lunch': 671, 'asss': 672, 'afffter': 673, 'yoga': 674, 'quite': 675, 'cake': 676, 'tttoo': 677, 'fffound': 678, 'onlyyy': 679, 'tttook': 680, 'lead': 681, 'bbby': 682, 'intooo': 683, 'agooo': 684, 'advance': 685, 'hearrrd': 686, 'saaaw': 687, 'enjoyeddd': 688, 'ifff': 689, 'verrry': 690, 'frooom': 691, 'toooo': 692, 'saiiid': 693, 'theee': 694, 'nottt': 695, 'frommm': 696, 'mettt': 697, 'beeeen': 698, 'starteddd': 699, 'veeery': 700, 'bbbut': 701, 'becaaause': 702, 'cherish': 703, 'kneeew': 704, 'ttthough': 705, 'nnnow': 706, 'allll': 707, 'alsooo': 708, 'sssometimes': 709, 'visiteddd': 710, 'iiinto': 711, 'oftennn': 712, 'home': 713, 'maddde': 714, 'gggave': 715, 'found': 716, 'aaago': 717, 'lllost': 718, 'lookeeed': 719, 'deep': 720, 'annn': 721, 'watcheeed': 722, 'playeeed': 723, 'basketball': 724, 'whiiile': 725, 'absent': 726, 'eveeer': 727, 'befffore': 728, 'veryyy': 729, 'stayeddd': 730, 'unk': 1}\n",
            "Count tokens: 730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z65grzBn-59X",
        "outputId": "dbad9204-18e7-42b6-cdd5-47147c416114",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def pad(x, length=None):\n",
        "       \n",
        "    if length is None:\n",
        "        \n",
        "        length = max([len(sentence) for sentence in x])\n",
        "        print(length)\n",
        "        \n",
        "    return length,pad_sequences(x, maxlen=length, padding='post')\n",
        "# Pad Tokenized output\n",
        "\n",
        "seqLen,pad_features = pad(text_tokenized)\n",
        "print(pad_features[5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "[ 7  8 12 24 14 22 25 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a621ZiTO-59Y",
        "outputId": "3c1e0c60-9b85-4dae-a2bb-9d1bd401f7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_size = len(text_tokenizer)+1 # adding 1 for zero value added in padding\n",
        "print(vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bastwAo-59Y"
      },
      "source": [
        "#print(pad_features)\n",
        "#seqLen = 34\n",
        "def hotcodSeq(pad_features):\n",
        "    \n",
        "    temp2 = np.zeros((len(pad_features),seqLen,vocab_size))\n",
        "\n",
        "    for i_seq in range((len(pad_features))):\n",
        "        #print(\"ii \"+str(i_seq))\n",
        "        #print(pad_features[i_seq])\n",
        "        for j_id in range(len(pad_features[i_seq])):\n",
        "            if(pad_features[i_seq][j_id]==18):\n",
        "                temp2[i_seq][j_id][pad_features[i_seq][j_id]] = 1\n",
        "            else:\n",
        "                temp2[i_seq][j_id][pad_features[i_seq][j_id]] = 1\n",
        "        \n",
        "        \n",
        "    return temp2\n",
        "    \n",
        "\n",
        "features_x = hotcodSeq(pad_features)\n",
        "print(features_x[5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbCMgVQ-59Z",
        "outputId": "630d1d68-dea8-4cb9-f9b0-75ff3c02130d"
      },
      "source": [
        "labels = np.array(trainSet[:,1])\n",
        "labels = labels.astype(int)\n",
        "print(labels[0])\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "(96000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tia2XQxu-59Z"
      },
      "source": [
        "np.random.seed(14567)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxVxU-ke-59Z",
        "outputId": "69d203b8-8713-4f2b-b47a-fb717041a06d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense,Dropout,InputLayer,Embedding\n",
        "from keras.layers.core import Flatten\n",
        "def lstmModel(batchSize):\n",
        "    \n",
        "    model = Sequential()\n",
        "    batch_size = batchSize\n",
        "    model.add(LSTM(50,batch_input_shape=(batch_size,seqLen,vocab_size),return_sequences=True,dropout=0.1,recurrent_dropout=0.1))#output dimensions batch_size,timesteps,20\n",
        "    model.add(LSTM(50))\n",
        "    #model.add(Flatten())\n",
        "    model.add(Dense(64,activation='relu'))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dense(8,activation='relu'))\n",
        "    model.add(Dense(2,activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "    return model\n",
        "model = lstmModel(4000)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (4000, 24, 50)            173800    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (4000, 50)                20200     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (4000, 64)                3264      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (4000, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (4000, 8)                 264       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (4000, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 199,626\n",
            "Trainable params: 199,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ20L4K6-59a",
        "outputId": "3f9d6887-9be3-4fd9-801c-c26e7409bf22"
      },
      "source": [
        "# fit the model\n",
        "model.fit(features_x,labels,epochs=500,batch_size=4000,shuffle=True,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "52000/96000 [===============>..............] - ETA: 1:48 - loss: 0.6891 - acc: 0.5336"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1m6U73Q-59a",
        "outputId": "16ea8137-36cf-4817-d62a-bd6b2be2be1e"
      },
      "source": [
        "print(model.metrics_names)\n",
        "\n",
        "model.evaluate(features_x,labels,batch_size=5000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "100000/100000 [==============================] - 3s 32us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4403184786438942, 0.7725400000810623]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARcf1X---59a",
        "outputId": "7232502c-cee6-4817-c456-a751f316ff44"
      },
      "source": [
        "def text_2_id(tokenizer,sentences):\n",
        "    dataset_int = []\n",
        "    for sent in sentences:\n",
        "        #print(sent)\n",
        "        sentSeq = []\n",
        "        for word in sent.split():\n",
        "            if word in tokenizer:\n",
        "                sentSeq.append(tokenizer[word])\n",
        "            else:\n",
        "                sentSeq.append(tokenizer['unk'])\n",
        "        #print(sentSeq)\n",
        "        dataset_int.append(sentSeq)\n",
        "            \n",
        "    #for sent in sentences:\n",
        "        #dataset_int.append([vocab_to_int[w] for word in sent.split() if (word in vocab_to_int):w = word ])\n",
        "    return dataset_int\n",
        "\n",
        "testSeq = text_2_id(text_tokenizer,testSet[:,0])\n",
        "seqLen,testPadSeq = pad(testSeq,seqLen)\n",
        "#print(testPadSeq)\n",
        "testLabels = np.array(testSet[:,1])\n",
        "#print(testPadSeq)\n",
        "test_features = hotcodSeq(testPadSeq)\n",
        "print(testLabels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHluq2td-59b",
        "outputId": "739040fe-a02f-4ddb-de92-4445d574cfe5"
      },
      "source": [
        "print(model.metrics_names)\n",
        "#model.evaluate(test_features[0:200,],testLabels[0:200,],batch_size=100)\n",
        "model.evaluate(test_features,testLabels,batch_size=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss', 'acc']\n",
            "30000/30000 [==============================] - 1s 30us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5203609764575958, 0.746833344300588]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}